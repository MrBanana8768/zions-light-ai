# ===============================================
# AI Model Deployment - Docker Compose Configuration
# ===============================================

# Version Control
VERSION=v2.2

# Required Secrets (MUST BE SET)
# Generate with: openssl rand -hex 32
WEBUI_SECRET_KEY=replace-with-64-character-secret-key-here
WEBUI_JWT_SECRET_KEY=replace-with-another-64-character-secret-key-here
API_SECRET_KEY=your-secure-api-bearer-token-here

# Port Configuration
WEBUI_PORT=3000
API_PORT=8000

# Production Proxy Ports (optional - for nginx-proxy service)
PROXY_HTTP_PORT=80
PROXY_HTTPS_PORT=443

# GPU Configuration
# Number of GPUs to allocate (1, 2, 4, etc.)
GPU_COUNT=1
# Number of model layers to run on GPU
GPU_LAYERS=35

# Model Configuration
CTX_SIZE=12288
THREADS=8

# Application Settings
ENABLE_SIGNUP=true
DATA_DIR=/app/data

# Logging Level (debug, info, warn, error)
LOG_LEVEL=info

# ===============================================
# GPU Configuration Examples
# ===============================================
# Single GPU (RTX 4060 Ti, A4000):
# GPU_COUNT=1
# GPU_LAYERS=28

# Dual GPU (2x RTX 4090):
# GPU_COUNT=2  
# GPU_LAYERS=35

# High-end (4x A100):
# GPU_COUNT=4
# GPU_LAYERS=35

# ===============================================
# Usage Instructions
# ===============================================
# 1. Copy this file: cp .env.example .env
# 2. Generate secrets: openssl rand -hex 32
# 3. Set GPU_COUNT based on your hardware
# 4. Adjust GPU_LAYERS for your VRAM capacity
# 5. Run: docker-compose up -d
#
# For production with SSL:
# docker-compose --profile production up -d
